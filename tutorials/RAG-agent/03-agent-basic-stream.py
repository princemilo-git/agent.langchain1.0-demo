from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

from dotenv import load_dotenv
from pyreadline3.console import event

load_dotenv("./env/.env")
# agentåŸºæœ¬ç”¨æ³•-æµå¼è¾“å‡ºï¼Œmessage by message å’Œ token by tokenä¸¤ç§æ–¹å¼

# æŒ‡å®šæ¨¡å‹
import os
model = ChatOpenAI(
    model="qwen-plus",  # DashScope æ”¯æŒçš„æ¨¡å‹å
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    api_key=os.getenv("DASHSCOPE_API_KEY"),  # å¿…é¡»æ˜¾å¼ä¼ å…¥æˆ–è®¾ç¯å¢ƒå˜é‡
    temperature=0.7
)

# å®šä¹‰å·¥å…·
def get_weather(city: str) -> str:
    """Get the weather in a given location."""
    return f"It's sunny in {city}~"

tools=[get_weather]

# åˆ›å»ºAgent
agent_base = create_agent(
    model=model,
    tools=tools,
)

# 1. values
# for event in agent_base.stream(
#     {"messages":[{
#         "role":"user",
#         "content":"what is the weather in Beijing"}]
#     },
#     stream_mode="values" # æ¶ˆæ¯è¾“å‡º
# ):
#     messages = event["messages"]
#     print(f"å†å²æ¶ˆæ¯ï¼š {len(messages)} æ¡")
#     # for message in messages:
#     #     message.pretty_print()
#     messages[len(messages)-1].pretty_print()

# 2. messages
for chunk in agent_base.stream(
    {"messages":[{
        "role":"user",
        "content":"what is the weather in Beijing"}]
    },
    stream_mode="messages" # token by token
):
    print( chunk[0].content, end="\n")


#
# It's sunny in Beijing~
# The
#  weather in
#  Beijing is sunny
# !
#  ğŸ˜Š